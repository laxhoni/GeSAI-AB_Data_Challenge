{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a69d821d",
   "metadata": {},
   "source": [
    "# 2. Feature engineering y entrenamiento del modelo de detección LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c87f2ce",
   "metadata": {},
   "source": [
    "Este notebook implementa un pipeline de entrenamiento robusto para la detección de fugas de agua. Debido al gran volumen de datos ($>75$ millones de registros) y las limitaciones de memoria RAM, se ha diseñado una estrategia de carga distribuida con Dask y muestreo inteligente.\n",
    "\n",
    "El objetivo es entrenar tres modelos de Gradient Boosting (LightGBM) independientes para predecir la probabilidad de fuga en tres horizontes temporales: Hoy (1h), Mañana (24h) y 7 Días (168h). Estos modelos alimentarán posteriormente el sistema de Meta-Análisis para la toma de decisiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf535e",
   "metadata": {},
   "source": [
    "## 2.1. Configuaración inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5969996",
   "metadata": {},
   "source": [
    "Definimos las rutas de los datos procesados y los parámetros globales del entrenamiento. Se establece una ventana de tiempo continua (Enero-Marzo) para garantizar la coherencia de las series temporales, y un porcentaje de subsampling para asegurar que el dataset quepa en la memoria RAM disponible durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1185bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c89797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congiguración del Proyecto\n",
    "FINAL_DATASET_PATH = '../data/processed-data/dataset_FINAL_COMPLETO/'\n",
    "ID_COLUMN = 'POLISSA_SUBM'\n",
    "\n",
    "# Definición de los horizontes de predicción (en número de registros/horas)\n",
    "HORIZONTES_PREDICCION = {'HOY': 1, 'MANANA': 24, '7DIAS': 168}\n",
    "\n",
    "# Configuración de fechas de entrenamiento\n",
    "TRAIN_START_DATE = '2024-01-01'\n",
    "TRAIN_END_DATE = '2024-06-30' \n",
    "\n",
    "# Usamos el 25% de los datos de ese rango de fechas para evitar ArrowMemoryError\n",
    "SUBSAMPLE_PERCENT = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c95dd8c",
   "metadata": {},
   "source": [
    "## 2.2. Selección de características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7817375b",
   "metadata": {},
   "source": [
    "Definimos explícitamente qué columnas son **Metadata** (no predictivas) y cuáles son las **Features Base** que alimentarán al modelo.\n",
    "Esta selección optimizada es crucial para reducir el consumo de memoria.\n",
    "\n",
    "Se realiza una selección explícita de variables (Feature Selection).\n",
    "\n",
    "* Se excluyen metadatos administrativos (IDs, fechas de facturación) y columnas redundantes para evitar data leakage y reducir la dimensionalidad.\n",
    "\n",
    "* Se seleccionan 32 variables clave agrupadas en: Consumo, Clima, Entorno Socioeconómico, Demografía e Infraestructura. Esta selección manual optimiza el rendimiento del modelo LightGBM y reduce el riesgo de sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e90ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas de metadatos (para exclusión)\n",
    "METADATA_AND_TARGET_COLUMNS = [\n",
    "    'POLISSA_SUBM', 'NUMEROSERIECONTADOR', 'SECCIO_CENSAL', 'KEY_DISTRITO', 'KEY_SECCION', \n",
    "    'FECHA_HORA', 'FECHA', 'HORA', 'DATA_INI_FACT', 'DATA_FIN_FACT', 'FECHA_HORA_CRONO',\n",
    "    'FUGA_DETECTADA', 'FUGA_REITERADA', \n",
    "]\n",
    "\n",
    "# Feature base (Numéricas + Categóricas)\n",
    "FEATURE_COLUMNS_BASE = [\n",
    "    'CONSUMO_REAL', 'TEMP_MEDIA', 'TEMP_MIN', 'TEMP_MAX', 'PRECIPITACION', \n",
    "    'HUMEDAD_RELATIVA_MEDIA', 'FESTIVO', 'Renda_Media_Euros', 'Antig_1901_a_1940', \n",
    "    'Antig_1941_a_1950', 'Antig_1951_a_1960', 'Antig_1961_a_1970', 'Antig_1971_a_1980', \n",
    "    'Antig_1981_a_1990', 'Antig_1991_a_2000', 'Antig_2001_a_2010', 'Antig_2011_a_2020', \n",
    "    'Antig_2021_a_2030', 'Antig_Menor_1901', 'Pob_0_14_anys', 'Pob_15_24_anys', \n",
    "    'Pob_25_39_anys', 'Pob_40_64_anys', 'Pob_65_o_mas', 'Pob_Total_Seccio', \n",
    "    'Pct_Pob_0_14_anys', 'Pct_Pob_15_24_anys', 'Pct_Pob_25_39_anys', \n",
    "    'Pct_Pob_40_64_anys', 'Pct_Pob_65_o_mas', 'Num_Obres_Recents',\n",
    "    'US_AIGUA_SUBM', 'TIPO_DIA' \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3febc8cc",
   "metadata": {},
   "source": [
    "## 2.3. Carga de datos distribuída (Solución Anti-Memoria)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e236b1",
   "metadata": {},
   "source": [
    "Utilizamos **Dask** para cargar el dataset masivo y realizar un muestreo aleatorio (`.sample()`) antes de cargarlo en la memoria RAM. Esto evita el error `ArrowMemoryError` al no intentar leer los 16GB de golpe.\n",
    "\n",
    "Para superar el ArrowMemoryError causado por el tamaño del dataset completo ($16 \\text{ GiB}$), implementamos una estrategia de carga en dos fases:\n",
    "* Filtrado Distribuido (Lazy): Usamos Dask para filtrar por rango de fechas y aplicar un muestreo aleatorio (sample) sin cargar los datos en memoria.\n",
    "\n",
    "* Consolidación (Compute): Solo traemos a la memoria RAM de Pandas el subconjunto resultante, garantizando que el entorno de trabajo se mantenga estable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d01a256d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. Carga Distribuida y Muestreo ---\n",
      "Filtrando periodo: 2024-01-01 a 2024-06-30...\n",
      "Aplicando muestreo del 25% sobre el periodo seleccionado...\n",
      "✅ Dataset cargado en RAM: 9238937 filas.\n",
      "Ordenando datos...\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 2. Carga Distribuida y Muestreo ---\")\n",
    "\n",
    "try:\n",
    "    # 1. Cargar puntero Dask (Lazy load)\n",
    "    df_dask_full = dd.read_parquet(FINAL_DATASET_PATH)\n",
    "    \n",
    "    # 2. Asegurar formato de fecha\n",
    "    df_dask_full['FECHA'] = dd.to_datetime(df_dask_full['FECHA'])\n",
    "    \n",
    "    # 3. APLICAR FILTRO DE FECHAS (Paso 1: Seleccionar el periodo correcto)\n",
    "    print(f\"Filtrando periodo: {TRAIN_START_DATE} a {TRAIN_END_DATE}...\")\n",
    "    df_dask_window = df_dask_full[\n",
    "        (df_dask_full['FECHA'] >= TRAIN_START_DATE) & \n",
    "        (df_dask_full['FECHA'] <= TRAIN_END_DATE)\n",
    "    ]\n",
    "    \n",
    "    # 4. APLICAR SUBSAMPLING (Paso 2: Reducir volumen para la RAM)\n",
    "    if SUBSAMPLE_PERCENT < 1.0:\n",
    "        print(f\"Aplicando muestreo del {SUBSAMPLE_PERCENT:.0%} sobre el periodo seleccionado...\")\n",
    "        # .sample() en Dask es distribuido y eficiente\n",
    "        df_dask_final = df_dask_window.sample(frac=SUBSAMPLE_PERCENT, random_state=42)\n",
    "    else:\n",
    "        df_dask_final = df_dask_window\n",
    "    \n",
    "    # 5. CONSOLIDACIÓN EN RAM (Ahora sí es seguro hacer .compute())\n",
    "    df = df_dask_final.compute()\n",
    "    \n",
    "    print(f\"✅ Dataset cargado en RAM: {df.shape[0]} filas.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR CRÍTICO: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 6. Ordenamiento cronológico final (Vital para los Lags)\n",
    "print(\"Ordenando datos...\")\n",
    "df['FECHA_HORA_CRONO'] = pd.to_datetime(df['FECHA'].astype(str) + ' ' + df['HORA'].astype(str), errors='coerce')\n",
    "df = df.sort_values(by=[ID_COLUMN, 'FECHA_HORA_CRONO']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d652e",
   "metadata": {},
   "source": [
    "## 2.4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d708b9",
   "metadata": {},
   "source": [
    "Dado que LightGBM no es un modelo secuencial (como LSTM), debemos crear explícitamente características que capturen la temporalidad y la tendencia:\n",
    "\n",
    "* Lags (Retardos): Variables que indican el consumo y clima de hace 1h, 6h, 12h, 24h y 72h.\n",
    "\n",
    "* Rolling Windows (Medias Móviles): Cálculo de la media y desviación estándar del consumo en los últimos 7 días para establecer una \"línea base\" de comportamiento normal.\n",
    "\n",
    "* Ratios de Desviación: Nuevas variables ingenieriles (RATIO_CONSUMO_MEDIA) que cuantifican cuánto se desvía el consumo actual respecto a su media histórica, facilitando la detección de anomalías de volumen.\n",
    "\n",
    "* Targets: Generación de las variables objetivo desplazadas hacia el futuro para los tres horizontes de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90abafa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creando Lags: 100%|██████████| 3/3 [00:06<00:00,  2.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# Definición de Features (Ingeniería de Características)\n",
    "LAG_FEATURES = ['CONSUMO_REAL', 'TEMP_MEDIA', 'PRECIPITACION']\n",
    "LAG_STEPS = [1, 6, 12, 24, 72] \n",
    "\n",
    "for col in tqdm(LAG_FEATURES, desc=\"Creando Lags\"):\n",
    "    for lag in LAG_STEPS:\n",
    "        # Al estar ordenado por Cliente+Fecha, el shift funciona correctamente\n",
    "        df[f'{col}_LAG_{lag}H'] = df.groupby(ID_COLUMN)[col].shift(lag)\n",
    "\n",
    "# Rolling (Ventana móvil de 7 días)\n",
    "WINDOW_SIZE = 168\n",
    "df['CONSUMO_ROLLING_MEAN_7D'] = df.groupby(ID_COLUMN)['CONSUMO_REAL'].transform(lambda x: x.rolling(WINDOW_SIZE, min_periods=1).mean())\n",
    "df['CONSUMO_ROLLING_STD_7D'] = df.groupby(ID_COLUMN)['CONSUMO_REAL'].transform(lambda x: x.rolling(WINDOW_SIZE, min_periods=1).std())\n",
    "\n",
    "\n",
    "# --- *** MEJORA: RATIOS DE DESVIACIÓN (NUEVO) *** ---\n",
    "# Estas features le gritan al modelo: \"¡Oye, esto es 5 veces más alto de lo normal!\"\n",
    "epsilon = 0.001 # Para evitar división por cero\n",
    "df['RATIO_CONSUMO_MEDIA_7D'] = df['CONSUMO_REAL'] / (df['CONSUMO_ROLLING_MEAN_7D'] + epsilon)\n",
    "df['DIFF_CONSUMO_MEDIA_7D'] = df['CONSUMO_REAL'] - df['CONSUMO_ROLLING_MEAN_7D']\n",
    "\n",
    "\n",
    "# Targets (Desplazamos hacia atrás para ver el futuro)\n",
    "TARGET_COLS = ['TARGET_HOY', 'TARGET_MANANA', 'TARGET_7DIAS']\n",
    "df['TARGET_HOY'] = df['FUGA_DETECTADA'].shift(-1)\n",
    "df['TARGET_MANANA'] = df['FUGA_DETECTADA'].shift(-24)\n",
    "df['TARGET_7DIAS'] = df['FUGA_DETECTADA'].shift(-168)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8dbc84",
   "metadata": {},
   "source": [
    "## 2.5. Preparación para el set de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8480c001",
   "metadata": {},
   "source": [
    "Preparamos las matrices finales para el modelo:\n",
    "\n",
    "* Limpieza de Nulos: Eliminamos las filas iniciales y finales que contienen NaN debido a la generación de Lags y Targets.\n",
    "\n",
    "* Definición de Tipos: Convertimos explícitamente las variables categóricas (TIPO_DIA, US_AIGUA_SUBM) al tipo category de Pandas para que LightGBM las procese de forma óptima.\n",
    "\n",
    "* Time-Split: Dividimos los datos cronológicamente (80% Pasado para Entrenar, 20% Futuro para Test) para simular un escenario de producción real y evitar mirar al futuro (look-ahead bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8fe7cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. Definición de Sets y Formateo ---\n",
      "Features finales para el entrenamiento (X): 52 columnas.\n",
      "Ejemplo de features incluidas: ['PRECIPITACION_LAG_72H', 'CONSUMO_ROLLING_MEAN_7D', 'CONSUMO_ROLLING_STD_7D', 'RATIO_CONSUMO_MEDIA_7D', 'DIFF_CONSUMO_MEDIA_7D']\n",
      "Set de Entrenamiento (Pasado): 7245110 filas\n",
      "Set de Prueba (Futuro/Simulación): 1811278 filas\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Definición de Sets y Formateo Final ---\n",
    "print(\"\\n--- 4. Definición de Sets y Formateo ---\")\n",
    "\n",
    "# 4.1. Definición de X_COLS (Lógica de Sustracción - MÁS SEGURA)\n",
    "# En lugar de listar qué queremos, listamos qué NO queremos.\n",
    "# Así, las nuevas features (Ratios, Diffs) entran automáticamente.\n",
    "\n",
    "COLS_TO_EXCLUDE = METADATA_AND_TARGET_COLUMNS + TARGET_COLS + ['FECHA_HORA_CRONO']\n",
    "\n",
    "# X_COLS = Todas las columnas presentes MENOS las excluidas\n",
    "X_COLS = [col for col in df.columns if col not in COLS_TO_EXCLUDE]\n",
    "\n",
    "print(f\"Features finales para el entrenamiento (X): {len(X_COLS)} columnas.\")\n",
    "print(f\"Ejemplo de features incluidas: {X_COLS[-5:]}\") # Verificamos que estén las nuevas\n",
    "\n",
    "# 4.2. Eliminamos NaNs resultantes del lagging y shifting\n",
    "# Usamos el target más lejano y las nuevas features como referencia\n",
    "df = df.dropna(subset=['TARGET_7DIAS'] + X_COLS) \n",
    "\n",
    "# 4.3. Definición de Features Categóricas (para LightGBM)\n",
    "CATEGORICAL_COLS = ['US_AIGUA_SUBM', 'TIPO_DIA'] \n",
    "for col in CATEGORICAL_COLS:\n",
    "    if col in X_COLS:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "# 4.4. Aplicando Time-Split Cronológico (80% Train, 20% Test)\n",
    "TEST_SIZE_PERCENTAGE = 0.20\n",
    "split_index = int(len(df) * (1 - TEST_SIZE_PERCENTAGE))\n",
    "\n",
    "df_train = df.iloc[:split_index].copy()\n",
    "df_test = df.iloc[split_index:].copy()\n",
    "\n",
    "print(f\"Set de Entrenamiento (Pasado): {df_train.shape[0]} filas\")\n",
    "print(f\"Set de Prueba (Futuro/Simulación): {df_test.shape[0]} filas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c1e5ca",
   "metadata": {},
   "source": [
    "## 2.6. Entrenamiento del modelo LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48594e7b",
   "metadata": {},
   "source": [
    "Entrenamos los tres modelos (Hoy, Mañana, 7 Días) utilizando un bucle optimizado para estabilidad en Windows:\n",
    "\n",
    "* Estabilidad: Se fuerza n_jobs=1 y force_col_wise=True para evitar conflictos de memoria y errores de acceso (Access Violation).\n",
    "\n",
    "* Robustez: Se realiza una limpieza final de tipos numéricos (eliminación de comas decimales) justo antes del entrenamiento.\n",
    "\n",
    "* Validación: Se utiliza un conjunto de validación interno (15% del train) con Early Stopping para detener el entrenamiento automáticamente cuando el modelo deja de aprender, preveniendo el sobreajuste.\n",
    "\n",
    "* Persistencia: Los modelos resultantes se guardan en formato .joblib para su despliegue en la aplicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d60c9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\n",
      "ENTRENAMIENTO DEL MODELO LIGHTGBM (MODO SEGURO)\n",
      "\n",
      "------------------------------------------------------------\n",
      "Preparando matriz X única...\n",
      "Matriz X preparada: (7245110, 52)\n",
      "\n",
      "[PROCESANDO] TARGET_HOY...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.982559\n",
      "\n",
      "[PROCESANDO] TARGET_MANANA...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.980912\n",
      "\n",
      "[PROCESANDO] TARGET_7DIAS...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.971041\n",
      "\n",
      "✅ Todos los modelos han sido entrenados y guardados.\n"
     ]
    }
   ],
   "source": [
    "# 2.6. Entrenamiento del modelo LightGBM (Versión Estable Windows)\n",
    "import gc\n",
    "\n",
    "print(\"---\"*20)\n",
    "print(\"\\nENTRENAMIENTO DEL MODELO LIGHTGBM (MODO SEGURO)\\n\")\n",
    "print(\"---\"*20)\n",
    "\n",
    "modelos_finales = {}\n",
    "output_dir = '../data/processed-data/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- 1. PREPARACIÓN ÚNICA DE LA MATRIZ X ---\n",
    "print(\"Preparando matriz X única...\")\n",
    "X_base = df_train[X_COLS].copy()\n",
    "\n",
    "# Limpieza de tipos (Una sola vez)\n",
    "num_cols = [c for c in X_COLS if c not in CATEGORICAL_COLS]\n",
    "for col in num_cols:\n",
    "    if X_base[col].dtype == 'object':\n",
    "        X_base[col] = X_base[col].astype(str).str.replace(',', '.', regex=False)\n",
    "    X_base[col] = pd.to_numeric(X_base[col], errors='coerce').fillna(0.0)\n",
    "\n",
    "for col in CATEGORICAL_COLS:\n",
    "    if col in X_base.columns:\n",
    "        X_base[col] = X_base[col].astype(str).astype('category')\n",
    "\n",
    "print(f\"Matriz X preparada: {X_base.shape}\")\n",
    "\n",
    "# --- 2. BUCLE DE ENTRENAMIENTO ---\n",
    "for target_col in TARGET_COLS:\n",
    "    print(f\"\\n[PROCESANDO] {target_col}...\")\n",
    "    \n",
    "    y = df_train[target_col].astype(int)\n",
    "\n",
    "    # División interna\n",
    "    X_fit, X_val, y_fit, y_val = train_test_split(\n",
    "        X_base, y, test_size=0.15, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    # --- CONFIGURACIÓN (Corrección de Estabilidad) ---\n",
    "    lgbm = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='auc', \n",
    "        is_unbalance=True,\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        n_jobs=1,  # <--- CRÍTICO: Usar 1 núcleo evita el Access Violation en Windows\n",
    "        random_state=42,\n",
    "        verbose=-1,\n",
    "        force_col_wise=True\n",
    "    )\n",
    "    \n",
    "    # --- ENTRENAMIENTO (Con copias de seguridad) ---\n",
    "    lgbm.fit(\n",
    "        X_fit.copy(), y_fit.copy(), # Copias explícitas\n",
    "        categorical_feature=[c for c in X_COLS if c in CATEGORICAL_COLS],\n",
    "        eval_set=[(X_val.copy(), y_val.copy())], # Copias explícitas\n",
    "        callbacks=[lgb.early_stopping(50, verbose=True)]\n",
    "    )\n",
    "    \n",
    "    modelos_finales[target_col] = lgbm\n",
    "    joblib.dump(lgbm, os.path.join(output_dir, f'lgbm_model_{target_col}.joblib'))\n",
    "    \n",
    "    del X_fit, X_val, y_fit, y_val, lgbm\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n✅ Todos los modelos han sido entrenados y guardados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9204cf79",
   "metadata": {},
   "source": [
    "## 2.7. Evaluación final del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea601fb1",
   "metadata": {},
   "source": [
    "Evaluamos el rendimiento de los modelos sobre el conjunto de prueba (datos futuros no vistos). Además de las métricas estándar (AUC-ROC, AUC-PR), implementamos una Búsqueda de Umbral Óptimo (Threshold Tuning).\n",
    "\n",
    "Analizamos cómo varía la Precisión y el Recall al cambiar el umbral de decisión (0.3, 0.4, 0.5, 0.6) para encontrar el punto de equilibrio que maximice la detección de fugas reales (F1-Score) sin disparar las falsas alarmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca42be56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\n",
      "EVALUACIÓN FINAL (TEST SET) \n",
      "\n",
      "------------------------------------------------------------\n",
      "============================================================\n",
      "RESULTADOS PARA: TARGET_HOY\n",
      "AUC-PR: 0.8685 | AUC-ROC: 0.7288\n",
      "------------------------------------------------------------\n",
      "Umbral     Precision       Recall          F1-Score  \n",
      "0.3        0.8241          0.6987          0.7562    \n",
      "0.4        0.8333          0.6152          0.7078    \n",
      "0.5        0.8464          0.5354          0.6559    \n",
      "0.6        0.8617          0.4728          0.6106    \n",
      "------------------------------------------------------------\n",
      "✅ RECOMENDACIÓN: Usar umbral > 0.3 para este horizonte.\n",
      "============================================================\n",
      "RESULTADOS PARA: TARGET_MANANA\n",
      "AUC-PR: 0.8578 | AUC-ROC: 0.7126\n",
      "------------------------------------------------------------\n",
      "Umbral     Precision       Recall          F1-Score  \n",
      "0.3        0.8186          0.6573          0.7291    \n",
      "0.4        0.8314          0.5994          0.6966    \n",
      "0.5        0.8386          0.5206          0.6424    \n",
      "0.6        0.8539          0.4415          0.5821    \n",
      "------------------------------------------------------------\n",
      "✅ RECOMENDACIÓN: Usar umbral > 0.3 para este horizonte.\n",
      "============================================================\n",
      "RESULTADOS PARA: TARGET_7DIAS\n",
      "AUC-PR: 0.8530 | AUC-ROC: 0.7144\n",
      "------------------------------------------------------------\n",
      "Umbral     Precision       Recall          F1-Score  \n",
      "0.3        0.8201          0.6838          0.7458    \n",
      "0.4        0.8330          0.5982          0.6963    \n",
      "0.5        0.8385          0.4980          0.6249    \n",
      "0.6        0.8543          0.4038          0.5484    \n",
      "------------------------------------------------------------\n",
      "✅ RECOMENDACIÓN: Usar umbral > 0.3 para este horizonte.\n",
      "\n",
      "✅ Archivo de análisis guardado: ../data/analisis_predicciones.csv\n",
      "✅ ENTRENAMIENTO COMPLETADO.\n"
     ]
    }
   ],
   "source": [
    "# Evaluación Final en el Test Set\n",
    "print(\"---\"*20)\n",
    "print(\"\\nEVALUACIÓN FINAL (TEST SET) \\n\")\n",
    "print(\"---\"*20)\n",
    "\n",
    "# Preparamos X_test (Limpieza de tipos igual que en train)\n",
    "X_test_final = df_test[X_COLS].copy()\n",
    "num_cols = [c for c in X_COLS if c not in CATEGORICAL_COLS]\n",
    "for col in num_cols:\n",
    "    if X_test_final[col].dtype == 'object':\n",
    "        X_test_final[col] = X_test_final[col].astype(str).str.replace(',', '.', regex=False)\n",
    "    X_test_final[col] = pd.to_numeric(X_test_final[col], errors='coerce').fillna(0.0)\n",
    "\n",
    "# DataFrame para guardar resultados\n",
    "df_resultados = df_test[[ID_COLUMN, 'FECHA_HORA_CRONO']].copy()\n",
    "\n",
    "for target_col, modelo in modelos_finales.items():\n",
    "    y_test_final = df_test[target_col].astype(int)\n",
    "    \n",
    "    # 1. Predicción de Probabilidad\n",
    "    y_pred_proba = modelo.predict_proba(X_test_final, raw_score=False)[:, 1]\n",
    "    \n",
    "    # Guardar en CSV\n",
    "    df_resultados[f'PROB_{target_col}'] = y_pred_proba\n",
    "    df_resultados[f'REAL_{target_col}'] = y_test_final.values\n",
    "\n",
    "    # 2. Métricas Globales\n",
    "    auc_pr = average_precision_score(y_test_final, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_test_final, y_pred_proba)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"RESULTADOS PARA: {target_col}\")\n",
    "    print(f\"AUC-PR: {auc_pr:.4f} | AUC-ROC: {roc_auc:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # --- *** ESTRATEGIA: BÚSQUEDA DE UMBRAL ÓPTIMO *** ---\n",
    "    # Probamos umbrales más bajos para cazar más fugas (subir Recall)\n",
    "    thresholds = [0.3, 0.4, 0.5, 0.6]\n",
    "    \n",
    "    print(f\"{'Umbral':<10} {'Precision':<15} {'Recall':<15} {'F1-Score':<10}\")\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_thresh = 0.5\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        y_pred_custom = (y_pred_proba > thresh).astype(int)\n",
    "        report = classification_report(y_test_final, y_pred_custom, output_dict=True)\n",
    "        \n",
    "        # Métricas de la clase '1' (Fuga)\n",
    "        prec = report['1']['precision']\n",
    "        rec = report['1']['recall']\n",
    "        f1 = report['1']['f1-score']\n",
    "        \n",
    "        print(f\"{thresh:<10} {prec:<15.4f} {rec:<15.4f} {f1:<10.4f}\")\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = thresh\n",
    "            \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"✅ RECOMENDACIÓN: Usar umbral > {best_thresh} para este horizonte.\")\n",
    "\n",
    "# Exportar CSV\n",
    "csv_path = '../data/analisis_predicciones.csv'\n",
    "df_resultados.to_csv(csv_path, index=False, sep=';', decimal=',')\n",
    "print(f\"\\n✅ Archivo de análisis guardado: {csv_path}\")\n",
    "print(\"✅ ENTRENAMIENTO COMPLETADO.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e0494",
   "metadata": {},
   "source": [
    "## 2.8 Exportación de los resultados a CSV para test de Meta-Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc65fcb",
   "metadata": {},
   "source": [
    "Exportamos las probabilidades predichas y los valores reales a un archivo CSV (analisis_predicciones.csv). Este archivo será el input para el siguiente notebook (Meta-Análisis), donde aplicaremos la lógica de negocio y las reglas de tendencias (deltas) sin necesidad de re-ejecutar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ad179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar CSV para Meta-Análisis\n",
    "csv_path = '../data/processed-data/analisis_predicciones.csv'\n",
    "df_resultados.to_csv(csv_path, index=False, sep=';', decimal=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
