{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5326d43e",
   "metadata": {},
   "source": [
    "# Data Preparation for GeSAI - AB Data Challenge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d86dd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9856adb0",
   "metadata": {},
   "source": [
    "# 1. Preparación inicial del dataset AB3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8510e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  POLIZA_SUMINISTRO NUMEROSERIECONTADOR  CONSUMO_REAL          FECHA_HORA  \\\n",
      "0  U2DVJQEKG3Y56QXB    62TNP5RI2GUII6WB           9.0 2024-01-01 00:29:14   \n",
      "1  U2DVJQEKG3Y56QXB    62TNP5RI2GUII6WB           7.0 2024-01-01 01:29:14   \n",
      "2  U2DVJQEKG3Y56QXB    62TNP5RI2GUII6WB          10.0 2024-01-01 02:29:14   \n",
      "3  U2DVJQEKG3Y56QXB    62TNP5RI2GUII6WB           7.0 2024-01-01 03:29:14   \n",
      "4  U2DVJQEKG3Y56QXB    62TNP5RI2GUII6WB           7.0 2024-01-01 04:29:14   \n",
      "\n",
      "  DATA_INI_FACT DATA_FIN_FACT CREATED_MENSAJE CODIGO_MENSAJE TIPO_MENSAJE  \n",
      "0    2024-01-24    2024-03-26             NaT           None         None  \n",
      "1    2024-01-24    2024-03-26             NaT           None         None  \n",
      "2    2024-01-24    2024-03-26             NaT           None         None  \n",
      "3    2024-01-24    2024-03-26             NaT           None         None  \n",
      "4    2024-01-24    2024-03-26             NaT           None         None  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset from data/data-ab3.parquet\n",
    "df_ab3 = pd.read_parquet('../data/data_ab3.parquet')\n",
    "print(df_ab3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bd8ba3",
   "metadata": {},
   "source": [
    "## 1.1. Información básica de nuestro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d032d80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121834 entries, 0 to 121833\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   POLIZA_SUMINISTRO    121834 non-null  object        \n",
      " 1   NUMEROSERIECONTADOR  121834 non-null  object        \n",
      " 2   CONSUMO_REAL         106983 non-null  float64       \n",
      " 3   FECHA_HORA           121834 non-null  datetime64[us]\n",
      " 4   DATA_INI_FACT        121834 non-null  object        \n",
      " 5   DATA_FIN_FACT        121834 non-null  object        \n",
      " 6   CREATED_MENSAJE      99400 non-null   datetime64[us]\n",
      " 7   CODIGO_MENSAJE       99400 non-null   object        \n",
      " 8   TIPO_MENSAJE         99400 non-null   object        \n",
      "dtypes: datetime64[us](2), float64(1), object(6)\n",
      "memory usage: 8.4+ MB\n",
      "None\n",
      "\n",
      "Number of null values in each column:\n",
      "POLIZA_SUMINISTRO          0\n",
      "NUMEROSERIECONTADOR        0\n",
      "CONSUMO_REAL           14851\n",
      "FECHA_HORA                 0\n",
      "DATA_INI_FACT              0\n",
      "DATA_FIN_FACT              0\n",
      "CREATED_MENSAJE        22434\n",
      "CODIGO_MENSAJE         22434\n",
      "TIPO_MENSAJE           22434\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the DataFrame\n",
    "print('DataFrame Information:')\n",
    "print(df_ab3.info())\n",
    "\n",
    "# Print number of null values in each column\n",
    "print('\\nNumber of null values in each column:')\n",
    "print(df_ab3.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e6f107",
   "metadata": {},
   "source": [
    "## 1.2. Tratamiento de los valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2f79e",
   "metadata": {},
   "source": [
    "### 1.2.1. Imputación en valores nulos de la variable \"CONSUMO_REAL\"\n",
    "Dada la información proporcionada por el equipo de AB Data, cuando la variable \"CONSUMO_REAL\" tiene un valor NaN quiere decir que el valor registrado es un valor < 1, para el correcto funcionamiento de los modelos a desarrollar asumiremos que este valor NaN será \"0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df46ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of null values in CONSUMO_REAL after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Imputation of missing values in \"CONSUMO_REAL\" column\n",
    "df_ab3.fillna({'CONSUMO_REAL': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0ba7c7",
   "metadata": {},
   "source": [
    "### 1.2.2. Toma de decisiones sobre las variables \"CREATED_MENSAJE\", \"CODIGO_MENSAJE\" y \"TIPO_MENSAJE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1a1766",
   "metadata": {},
   "source": [
    "Estas 3 variables hacen referencia a la detección y comunicación de fuga ('FUITA'), así como a su reiteración ('REITERACIÓ DE FUITA). Para llevar a cabo nuestro modelo predictivo nos hará falta simplificar el proceso de detección de fuga por lo que se ha decidido retirar estas columnas y añadir una nueva columna binaria que indica 0 si no hay fuga y 1 si hay fuga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf60a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary column for leak detection\n",
    "df_ab3['FUGA_DETECTADA'] = df_ab3['TIPO_MENSAJE'].apply(lambda x: 1 if x in ['FUITA', 'REITERACIÓ DE FUITA'] else 0)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_ab3.drop(columns=['CREATED_MENSAJE', 'CODIGO_MENSAJE', 'TIPO_MENSAJE'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdb0247",
   "metadata": {},
   "source": [
    "### 1.2.3. Verificación de la imputación en valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e8d7c",
   "metadata": {},
   "source": [
    "Verificamos si hemos realizado una correcta imputación imprimiendo el número de valores nulos en cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dee7170b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in each column:\n",
      "POLIZA_SUMINISTRO      0\n",
      "NUMEROSERIECONTADOR    0\n",
      "CONSUMO_REAL           0\n",
      "DATA_INI_FACT          0\n",
      "DATA_FIN_FACT          0\n",
      "FUGA_DETECTADA         0\n",
      "FECHA                  0\n",
      "HORA                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print number of null values in each column\n",
    "print('Number of null values in each column:')\n",
    "print(df_ab3.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc2e90",
   "metadata": {},
   "source": [
    "## 1.3. Tratamiento de la variable \"FECHA_HORA\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff40dea2",
   "metadata": {},
   "source": [
    "Para una mayor claridad de nuestros datos se ha decidido separar la variable \"FECHA_HORA\" en dos variables distintas: \"FECHA\" y \"HORA\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b946ab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated DataFrame:\n",
      "  POLIZA_SUMINISTRO NUMEROSERIECONTADOR  CONSUMO_REAL DATA_INI_FACT  \\\n",
      "0  U2DVJQEKG3Y56QXB    62TNP5RI2GUII6WB           9.0    2024-01-24   \n",
      "1  U2DVJQEKG3Y56QXB    62TNP5RI2GUII6WB           7.0    2024-01-24   \n",
      "2  U2DVJQEKG3Y56QXB    62TNP5RI2GUII6WB          10.0    2024-01-24   \n",
      "3  U2DVJQEKG3Y56QXB    62TNP5RI2GUII6WB           7.0    2024-01-24   \n",
      "4  U2DVJQEKG3Y56QXB    62TNP5RI2GUII6WB           7.0    2024-01-24   \n",
      "\n",
      "  DATA_FIN_FACT  FUGA_DETECTADA       FECHA      HORA  \n",
      "0    2024-03-26               0  2024-01-01  00:29:14  \n",
      "1    2024-03-26               0  2024-01-01  01:29:14  \n",
      "2    2024-03-26               0  2024-01-01  02:29:14  \n",
      "3    2024-03-26               0  2024-01-01  03:29:14  \n",
      "4    2024-03-26               0  2024-01-01  04:29:14  \n"
     ]
    }
   ],
   "source": [
    "# Convert specified columns to datetime format\n",
    "for col in [\"FECHA_HORA\"]:\n",
    "    df_ab3[col] = pd.to_datetime(df_ab3[col], errors=\"coerce\")\n",
    "\n",
    "# Split 'FECHA_HORA' into separate date and time columns\n",
    "df_ab3['FECHA'] = df_ab3['FECHA_HORA'].dt.date\n",
    "df_ab3['HORA'] = df_ab3['FECHA_HORA'].dt.time\n",
    "\n",
    "# Drop the original 'FECHA_HORA' column\n",
    "df_ab3 = df_ab3.drop(columns=['FECHA_HORA'])\n",
    "\n",
    "# Display updated DataFrame \n",
    "print('\\nUpdated DataFrame:')\n",
    "print(df_ab3.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
