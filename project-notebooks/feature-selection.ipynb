{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf25e453",
   "metadata": {},
   "source": [
    "# 1. Ingeniería de Características y Creación de Secuencias LIGHTGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed66a464",
   "metadata": {},
   "source": [
    "## 2.1. Configuración e importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7226bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a846a0a",
   "metadata": {},
   "source": [
    "## 2.2. Carga "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e643a25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. Carga y Preparación Inicial ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "FINAL_DATASET_PATH = './dataset_FINAL_COMPLETO'\n",
    "\n",
    "# Definición de los horizontes de predicción (en número de registros/horas)\n",
    "HORIZONTES_PREDICCION = {\n",
    "    'HOY': 1, \n",
    "    'MANANA': 24, \n",
    "    '7DIAS': 168\n",
    "}\n",
    "ID_COLUMN = 'POLISSA_SUBM'\n",
    "\n",
    "# Lista de columnas de metadatos (para exclusión)\n",
    "METADATA_AND_TARGET_COLUMNS = [\n",
    "    'POLISSA_SUBM', 'NUMEROSERIECONTADOR', 'SECCIO_CENSAL', 'KEY_DISTRITO', 'KEY_SECCION', \n",
    "    'FECHA_HORA', 'FECHA', 'HORA', 'DATA_INI_FACT', 'DATA_FIN_FACT', 'FECHA_HORA_CRONO',\n",
    "    'FUGA_DETECTADA', 'FUGA_REITERADA', \n",
    "]\n",
    "\n",
    "# --- 2. Carga y Preparación de Datos ---\n",
    "print(\"--- 2. Carga y Preparación Inicial ---\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_parquet(FINAL_DATASET_PATH) \n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: No se encontró el dataset final en {FINAL_DATASET_PATH}.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017bd916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. Carga Distribuida y Muestreo ---\n",
      "Aplicando muestreo del 10%...\n",
      "Dataset cargado en RAM: 7501955 filas.\n",
      "Ordenando cronológicamente...\n",
      "\n",
      "--- 3. Ingeniería de Características ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creando Lags: 100%|██████████| 3/3 [00:05<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Finales (50): ['CONSUMO_REAL', 'TEMP_MEDIA', 'TEMP_MIN', 'TEMP_MAX', 'PRECIPITACION'] ...\n",
      "Train: 5848018 | Test: 1462005\n",
      "\n",
      "--- 5. ENTRENAMIENTO ---\n",
      "\n",
      "[PROCESANDO] TARGET_HOY...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.98047\n",
      "\n",
      "[PROCESANDO] TARGET_MANANA...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.978312\n",
      "\n",
      "[PROCESANDO] TARGET_7DIAS...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.966331\n",
      "\n",
      "--- 6. EVALUACIÓN FINAL (TEST SET) ---\n",
      "\n",
      ">>> RESULTADOS TARGET_HOY <<<\n",
      "AUC-PR: 0.8334 | AUC-ROC: 0.6690\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Fuga       0.37      0.77      0.50    434170\n",
      "        Fuga       0.82      0.45      0.59   1027835\n",
      "\n",
      "    accuracy                           0.55   1462005\n",
      "   macro avg       0.60      0.61      0.54   1462005\n",
      "weighted avg       0.69      0.55      0.56   1462005\n",
      "\n",
      "\n",
      ">>> RESULTADOS TARGET_MANANA <<<\n",
      "AUC-PR: 0.8460 | AUC-ROC: 0.7016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Fuga       0.39      0.76      0.51    434193\n",
      "        Fuga       0.83      0.49      0.62   1027812\n",
      "\n",
      "    accuracy                           0.57   1462005\n",
      "   macro avg       0.61      0.63      0.57   1462005\n",
      "weighted avg       0.70      0.57      0.59   1462005\n",
      "\n",
      "\n",
      ">>> RESULTADOS TARGET_7DIAS <<<\n",
      "AUC-PR: 0.8334 | AUC-ROC: 0.6747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Fuga       0.38      0.78      0.51    434564\n",
      "        Fuga       0.83      0.46      0.59   1027441\n",
      "\n",
      "    accuracy                           0.55   1462005\n",
      "   macro avg       0.60      0.62      0.55   1462005\n",
      "weighted avg       0.70      0.55      0.57   1462005\n",
      "\n",
      "\n",
      "✅ ENTRENAMIENTO COMPLETADO.\n"
     ]
    }
   ],
   "source": [
    "# --- 0. Configuración y Librerías ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# --- 1. CONFIGURACIÓN DEL PROYECTO ---\n",
    "FINAL_DATASET_PATH = './dataset_FINAL_COMPLETO'\n",
    "ID_COLUMN = 'POLISSA_SUBM'\n",
    "\n",
    "HORIZONTES_PREDICCION = {'HOY': 1, 'MANANA': 24, '7DIAS': 168}\n",
    "\n",
    "# Usamos el 10% de los datos para evitar ArrowMemoryError (16GB)\n",
    "SUBSAMPLE_PERCENT = 0.10 \n",
    "\n",
    "# Listas de Columnas\n",
    "METADATA_AND_TARGET_COLUMNS = [\n",
    "    'POLISSA_SUBM', 'NUMEROSERIECONTADOR', 'SECCIO_CENSAL', 'KEY_DISTRITO', 'KEY_SECCION', \n",
    "    'FECHA_HORA', 'FECHA', 'HORA', 'DATA_INI_FACT', 'DATA_FIN_FACT', 'FECHA_HORA_CRONO',\n",
    "    'FUGA_DETECTADA', 'FUGA_REITERADA', \n",
    "]\n",
    "\n",
    "# Feature base (Numéricas + Categóricas)\n",
    "FEATURE_COLUMNS_BASE = [\n",
    "    'CONSUMO_REAL', 'TEMP_MEDIA', 'TEMP_MIN', 'TEMP_MAX', 'PRECIPITACION', \n",
    "    'HUMEDAD_RELATIVA_MEDIA', 'FESTIVO', 'Renda_Media_Euros', 'Antig_1901_a_1940', \n",
    "    'Antig_1941_a_1950', 'Antig_1951_a_1960', 'Antig_1961_a_1970', 'Antig_1971_a_1980', \n",
    "    'Antig_1981_a_1990', 'Antig_1991_a_2000', 'Antig_2001_a_2010', 'Antig_2011_a_2020', \n",
    "    'Antig_2021_a_2030', 'Antig_Menor_1901', 'Pob_0_14_anys', 'Pob_15_24_anys', \n",
    "    'Pob_25_39_anys', 'Pob_40_64_anys', 'Pob_65_o_mas', 'Pob_Total_Seccio', \n",
    "    'Pct_Pob_0_14_anys', 'Pct_Pob_15_24_anys', 'Pct_Pob_25_39_anys', \n",
    "    'Pct_Pob_40_64_anys', 'Pct_Pob_65_o_mas', 'Num_Obres_Recents',\n",
    "    'US_AIGUA_SUBM', 'TIPO_DIA' \n",
    "]\n",
    "\n",
    "# --- 2. Carga y Muestreo del Dataset (DASK) ---\n",
    "print(\"--- 2. Carga Distribuida y Muestreo ---\")\n",
    "\n",
    "try:\n",
    "    df_dask_full = dd.read_parquet(FINAL_DATASET_PATH)\n",
    "    print(f\"Aplicando muestreo del {SUBSAMPLE_PERCENT:.0%}...\")\n",
    "    df_dask_sampled = df_dask_full.sample(frac=SUBSAMPLE_PERCENT, random_state=42)\n",
    "    df = df_dask_sampled.compute()\n",
    "    print(f\"Dataset cargado en RAM: {df.shape[0]} filas.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR CRÍTICO: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 2.1. Ordenamiento Cronológico\n",
    "print(\"Ordenando cronológicamente...\")\n",
    "df['FECHA_HORA_CRONO'] = pd.to_datetime(df['FECHA'].astype(str) + ' ' + df['HORA'].astype(str), errors='coerce')\n",
    "df = df.sort_values(by=[ID_COLUMN, 'FECHA_HORA_CRONO']).reset_index(drop=True)\n",
    "\n",
    "# --- 3. Ingeniería de Características ---\n",
    "print(\"\\n--- 3. Ingeniería de Características ---\")\n",
    "\n",
    "LAG_FEATURES = ['CONSUMO_REAL', 'TEMP_MEDIA', 'PRECIPITACION']\n",
    "LAG_STEPS = [1, 6, 12, 24, 72] \n",
    "\n",
    "for col in tqdm(LAG_FEATURES, desc=\"Creando Lags\"):\n",
    "    for lag in LAG_STEPS:\n",
    "        df[f'{col}_LAG_{lag}H'] = df.groupby(ID_COLUMN)[col].shift(lag)\n",
    "\n",
    "# Rolling\n",
    "WINDOW_SIZE = 168\n",
    "df['CONSUMO_ROLLING_MEAN_7D'] = df.groupby(ID_COLUMN)['CONSUMO_REAL'].transform(lambda x: x.rolling(WINDOW_SIZE, min_periods=1).mean())\n",
    "df['CONSUMO_ROLLING_STD_7D'] = df.groupby(ID_COLUMN)['CONSUMO_REAL'].transform(lambda x: x.rolling(WINDOW_SIZE, min_periods=1).std())\n",
    "\n",
    "# Targets\n",
    "TARGET_COLS = ['TARGET_HOY', 'TARGET_MANANA', 'TARGET_7DIAS']\n",
    "df['TARGET_HOY'] = df['FUGA_DETECTADA'].shift(-1)\n",
    "df['TARGET_MANANA'] = df['FUGA_DETECTADA'].shift(-24)\n",
    "df['TARGET_7DIAS'] = df['FUGA_DETECTADA'].shift(-168)\n",
    "\n",
    "# --- 4. Definición de Features Finales ---\n",
    "lag_cols = [c for c in df.columns if '_LAG_' in c or '_ROLLING_' in c]\n",
    "X_COLS = [c for c in FEATURE_COLUMNS_BASE + lag_cols if c in df.columns and c not in METADATA_AND_TARGET_COLUMNS]\n",
    "\n",
    "print(f\"Features Finales ({len(X_COLS)}): {X_COLS[:5]} ...\")\n",
    "\n",
    "# Limpieza de NaNs generados por Lags\n",
    "df = df.dropna(subset=['TARGET_7DIAS'] + X_COLS)\n",
    "\n",
    "# Definición de Categóricas\n",
    "CATEGORICAL_COLS = ['US_AIGUA_SUBM', 'TIPO_DIA']\n",
    "for col in CATEGORICAL_COLS:\n",
    "    if col in X_COLS:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "# Time Split\n",
    "split_index = int(len(df) * 0.80)\n",
    "df_train = df.iloc[:split_index].copy()\n",
    "df_test = df.iloc[split_index:].copy()\n",
    "\n",
    "print(f\"Train: {len(df_train)} | Test: {len(df_test)}\")\n",
    "\n",
    "# --- 5. Entrenamiento ---\n",
    "print(\"\\n--- 5. ENTRENAMIENTO ---\")\n",
    "modelos_finales = {}\n",
    "output_dir = '../data/modelos_finales/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for target_col in TARGET_COLS:\n",
    "    print(f\"\\n[PROCESANDO] {target_col}...\")\n",
    "    \n",
    "    # Preparar datos\n",
    "    X = df_train[X_COLS].copy()\n",
    "    y = df_train[target_col].astype(int)\n",
    "    \n",
    "    # --- LIMPIEZA DE TIPOS ROBUSTA (Anti-ValueError) ---\n",
    "    num_cols = [c for c in X_COLS if c not in CATEGORICAL_COLS]\n",
    "    for col in num_cols:\n",
    "        if X[col].dtype == 'object':\n",
    "            X[col] = X[col].astype(str).str.replace(',', '.', regex=False)\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce').fillna(0.0)\n",
    "\n",
    "    # División interna para validación (Early Stopping)\n",
    "    X_fit, X_val, y_fit, y_val = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
    "    \n",
    "    # --- CONFIGURACIÓN LIGHTGBM (Con métrica 'auc') ---\n",
    "    lgbm = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='auc', # <--- CORRECCIÓN CRÍTICA: Usamos 'auc' que es estándar\n",
    "        is_unbalance=True,\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    # --- ENTRENAMIENTO ---\n",
    "    lgbm.fit(\n",
    "        X_fit, y_fit,\n",
    "        categorical_feature=[c for c in X_COLS if c in CATEGORICAL_COLS],\n",
    "        eval_set=[(X_val, y_val)], # Set de validación explícito\n",
    "        eval_metric='auc', # <--- CORRECCIÓN CRÍTICA: Debe coincidir\n",
    "        callbacks=[lgb.early_stopping(50, verbose=True)]\n",
    "    )\n",
    "    \n",
    "    modelos_finales[target_col] = lgbm\n",
    "    joblib.dump(lgbm, os.path.join(output_dir, f'lgbm_model_{target_col}.joblib'))\n",
    "\n",
    "# --- 6. Evaluación Final ---\n",
    "print(\"\\n--- 6. EVALUACIÓN FINAL (TEST SET) ---\")\n",
    "\n",
    "# Preparamos X_test igual que X_train\n",
    "X_test_final = df_test[X_COLS].copy()\n",
    "for col in num_cols:\n",
    "    if X_test_final[col].dtype == 'object':\n",
    "        X_test_final[col] = X_test_final[col].astype(str).str.replace(',', '.', regex=False)\n",
    "    X_test_final[col] = pd.to_numeric(X_test_final[col], errors='coerce').fillna(0.0)\n",
    "\n",
    "for target_col, modelo in modelos_finales.items():\n",
    "    y_test_final = df_test[target_col].astype(int)\n",
    "    \n",
    "    # Predicción\n",
    "    y_pred_proba = modelo.predict_proba(X_test_final)[:, 1]\n",
    "    \n",
    "    # Métricas\n",
    "    auc_pr = average_precision_score(y_test_final, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_test_final, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\n>>> RESULTADOS {target_col} <<<\")\n",
    "    print(f\"AUC-PR: {auc_pr:.4f} | AUC-ROC: {roc_auc:.4f}\")\n",
    "    \n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    print(classification_report(y_test_final, y_pred, target_names=['No Fuga', 'Fuga']))\n",
    "\n",
    "print(\"\\n✅ ENTRENAMIENTO COMPLETADO.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb1bf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Guardando Modelos desde la Memoria ---\n",
      "✅ Modelo guardado exitosamente: ../data/modelos_finales/lgbm_model_TARGET_HOY.joblib\n",
      "✅ Modelo guardado exitosamente: ../data/modelos_finales/lgbm_model_TARGET_MANANA.joblib\n",
      "✅ Modelo guardado exitosamente: ../data/modelos_finales/lgbm_model_TARGET_7DIAS.joblib\n",
      "\n",
      "¡Todos los modelos han sido persistidos en disco!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# 1. Configurar dónde se guardarán\n",
    "output_dir = '../data/modelos_finales/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"--- Guardando Modelos desde la Memoria ---\")\n",
    "\n",
    "# 2. Verificar si la variable existe en memoria\n",
    "if 'modelos_finales' in locals() or 'modelos_finales' in globals():\n",
    "    \n",
    "    # 3. Recorrer el diccionario y guardar cada modelo\n",
    "    for target_col, modelo in modelos_finales.items():\n",
    "        filename = f'lgbm_model_{target_col}.joblib'\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        joblib.dump(modelo, filepath)\n",
    "        print(f\"✅ Modelo guardado exitosamente: {filepath}\")\n",
    "        \n",
    "    print(\"\\n¡Todos los modelos han sido persistidos en disco!\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ ERROR: No encuentro la variable 'modelos_finales' en la memoria.\")\n",
    "    print(\"Asegúrate de no haber reiniciado el kernel después del entrenamiento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bloque para Exportar Resultados a CSV ---\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"--- Generando CSV de Resultados ---\")\n",
    "\n",
    "# 1. Verificamos que existan los datos en memoria\n",
    "if 'df_test' in locals() and 'modelos_finales' in locals():\n",
    "    \n",
    "    # 2. Creamos un DataFrame base con la info del cliente\n",
    "    # (Asegúrate de incluir la fecha para el análisis temporal)\n",
    "    cols_info = [ID_COLUMN, 'FECHA_HORA_CRONO'] if 'FECHA_HORA_CRONO' in df_test.columns else [ID_COLUMN]\n",
    "    df_resultados = df_test[cols_info].copy()\n",
    "\n",
    "    # 3. Iteramos por cada modelo para añadir sus predicciones\n",
    "    for target_col, modelo in modelos_finales.items():\n",
    "        print(f\"Procesando predicciones para: {target_col}...\")\n",
    "        \n",
    "        # Preparar X_test (Mismo casting que en el entrenamiento para evitar errores)\n",
    "        X_test_iter = df_test[X_COLS].copy()\n",
    "        num_cols = [c for c in X_COLS if c not in CATEGORICAL_COLS]\n",
    "        for col in num_cols:\n",
    "            # Limpieza de tipos robusta\n",
    "            if X_test_iter[col].dtype == 'object':\n",
    "                X_test_iter[col] = X_test_iter[col].astype(str).str.replace(',', '.', regex=False)\n",
    "            X_test_iter[col] = pd.to_numeric(X_test_iter[col], errors='coerce').fillna(0.0)\n",
    "            \n",
    "        # Predecir Probabilidad (La \"Confianza\" del modelo)\n",
    "        probs = modelo.predict_proba(X_test_iter, raw_score=False)[:, 1]\n",
    "        \n",
    "        # Guardar en el DataFrame\n",
    "        df_resultados[f'PROB_{target_col}'] = probs\n",
    "        df_resultados[f'REAL_{target_col}'] = df_test[target_col].astype(int).values\n",
    "\n",
    "    # 4. Guardar a CSV\n",
    "    ruta_csv = '../data/analisis_predicciones.csv'\n",
    "    df_resultados.to_csv(ruta_csv, index=False, sep=';', decimal=',') \n",
    "    # Nota: Uso sep=';' y decimal=',' para que Excel en español lo abra directo\n",
    "    \n",
    "    print(f\"\\n✅ Archivo guardado exitosamente: {ruta_csv}\")\n",
    "    print(\"Columnas generadas:\", df_resultados.columns.tolist())\n",
    "\n",
    "else:\n",
    "    print(\"❌ Error: No se encuentran 'df_test' o 'modelos_finales' en memoria. Ejecuta el entrenamiento primero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ba59469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset ../data/analisis_predicciones.csv\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df_analysis = pd.read_csv('../data/analisis_predicciones.csv', sep=';', decimal=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0e7f58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POLISSA_SUBM</th>\n",
       "      <th>FECHA_HORA_CRONO</th>\n",
       "      <th>PROB_TARGET_HOY</th>\n",
       "      <th>REAL_TARGET_HOY</th>\n",
       "      <th>PROB_TARGET_MANANA</th>\n",
       "      <th>REAL_TARGET_MANANA</th>\n",
       "      <th>PROB_TARGET_7DIAS</th>\n",
       "      <th>REAL_TARGET_7DIAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TLFF6N34NTT4Y4EL</td>\n",
       "      <td>2024-11-03 13:27:29</td>\n",
       "      <td>0.975845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TLFF6N34NTT4Y4EL</td>\n",
       "      <td>2024-11-03 14:27:28</td>\n",
       "      <td>0.975845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TLFF6N34NTT4Y4EL</td>\n",
       "      <td>2024-11-03 16:27:28</td>\n",
       "      <td>0.975845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TLFF6N34NTT4Y4EL</td>\n",
       "      <td>2024-11-03 16:27:28</td>\n",
       "      <td>0.975845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TLFF6N34NTT4Y4EL</td>\n",
       "      <td>2024-11-03 16:27:28</td>\n",
       "      <td>0.975845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       POLISSA_SUBM     FECHA_HORA_CRONO  PROB_TARGET_HOY  REAL_TARGET_HOY  \\\n",
       "0  TLFF6N34NTT4Y4EL  2024-11-03 13:27:29         0.975845                1   \n",
       "1  TLFF6N34NTT4Y4EL  2024-11-03 14:27:28         0.975845                1   \n",
       "2  TLFF6N34NTT4Y4EL  2024-11-03 16:27:28         0.975845                1   \n",
       "3  TLFF6N34NTT4Y4EL  2024-11-03 16:27:28         0.975845                1   \n",
       "4  TLFF6N34NTT4Y4EL  2024-11-03 16:27:28         0.975845                1   \n",
       "\n",
       "   PROB_TARGET_MANANA  REAL_TARGET_MANANA  PROB_TARGET_7DIAS  \\\n",
       "0            0.959602                   1           0.961532   \n",
       "1            0.959602                   1           0.961532   \n",
       "2            0.959602                   1           0.961532   \n",
       "3            0.959602                   1           0.961532   \n",
       "4            0.959602                   1           0.961532   \n",
       "\n",
       "   REAL_TARGET_7DIAS  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4de08c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POLISSA_SUBM</th>\n",
       "      <th>DATA_INI_FACT</th>\n",
       "      <th>DATA_FIN_FACT</th>\n",
       "      <th>US_AIGUA_SUBM</th>\n",
       "      <th>SECCIO_CENSAL</th>\n",
       "      <th>NUMEROSERIECONTADOR</th>\n",
       "      <th>CONSUMO_REAL</th>\n",
       "      <th>FECHA_HORA</th>\n",
       "      <th>FUGA_DETECTADA</th>\n",
       "      <th>FUGA_REITERADA</th>\n",
       "      <th>...</th>\n",
       "      <th>PRECIPITACION_LAG_1H</th>\n",
       "      <th>PRECIPITACION_LAG_6H</th>\n",
       "      <th>PRECIPITACION_LAG_12H</th>\n",
       "      <th>PRECIPITACION_LAG_24H</th>\n",
       "      <th>PRECIPITACION_LAG_72H</th>\n",
       "      <th>CONSUMO_ROLLING_MEAN_7D</th>\n",
       "      <th>CONSUMO_ROLLING_STD_7D</th>\n",
       "      <th>TARGET_HOY</th>\n",
       "      <th>TARGET_MANANA</th>\n",
       "      <th>TARGET_7DIAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>22KX53JQU5AD26SG</td>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>2023-06-23 00:00:00</td>\n",
       "      <td>DOMÈSTIC</td>\n",
       "      <td>0801908047</td>\n",
       "      <td>KKF44CYBRFOXT57S</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2024-01-04 21:38:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>92.164384</td>\n",
       "      <td>28.278876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>22KX53JQU5AD26SG</td>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>2023-06-23 00:00:00</td>\n",
       "      <td>DOMÈSTIC</td>\n",
       "      <td>0801908047</td>\n",
       "      <td>KKF44CYBRFOXT57S</td>\n",
       "      <td>123.0</td>\n",
       "      <td>2024-01-04 23:38:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>92.581081</td>\n",
       "      <td>28.312351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>22KX53JQU5AD26SG</td>\n",
       "      <td>2023-08-23 00:00:00</td>\n",
       "      <td>2023-10-24 00:00:00</td>\n",
       "      <td>DOMÈSTIC</td>\n",
       "      <td>0801908047</td>\n",
       "      <td>KKF44CYBRFOXT57S</td>\n",
       "      <td>123.0</td>\n",
       "      <td>2024-01-04 23:38:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>92.986667</td>\n",
       "      <td>28.338920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>22KX53JQU5AD26SG</td>\n",
       "      <td>2024-06-26 00:00:00</td>\n",
       "      <td>2024-08-23 00:00:00</td>\n",
       "      <td>DOMÈSTIC</td>\n",
       "      <td>0801908047</td>\n",
       "      <td>KKF44CYBRFOXT57S</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2024-01-05 00:38:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>92.842105</td>\n",
       "      <td>28.177557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>22KX53JQU5AD26SG</td>\n",
       "      <td>2023-10-24 00:00:00</td>\n",
       "      <td>2023-12-22 00:00:00</td>\n",
       "      <td>DOMÈSTIC</td>\n",
       "      <td>0801908047</td>\n",
       "      <td>KKF44CYBRFOXT57S</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2024-01-05 02:38:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8,4</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>92.701299</td>\n",
       "      <td>28.018821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        POLISSA_SUBM        DATA_INI_FACT        DATA_FIN_FACT US_AIGUA_SUBM  \\\n",
       "72  22KX53JQU5AD26SG  2023-04-25 00:00:00  2023-06-23 00:00:00      DOMÈSTIC   \n",
       "73  22KX53JQU5AD26SG  2023-04-25 00:00:00  2023-06-23 00:00:00      DOMÈSTIC   \n",
       "74  22KX53JQU5AD26SG  2023-08-23 00:00:00  2023-10-24 00:00:00      DOMÈSTIC   \n",
       "75  22KX53JQU5AD26SG  2024-06-26 00:00:00  2024-08-23 00:00:00      DOMÈSTIC   \n",
       "76  22KX53JQU5AD26SG  2023-10-24 00:00:00  2023-12-22 00:00:00      DOMÈSTIC   \n",
       "\n",
       "   SECCIO_CENSAL NUMEROSERIECONTADOR  CONSUMO_REAL          FECHA_HORA  \\\n",
       "72    0801908047    KKF44CYBRFOXT57S         134.0 2024-01-04 21:38:37   \n",
       "73    0801908047    KKF44CYBRFOXT57S         123.0 2024-01-04 23:38:38   \n",
       "74    0801908047    KKF44CYBRFOXT57S         123.0 2024-01-04 23:38:38   \n",
       "75    0801908047    KKF44CYBRFOXT57S          82.0 2024-01-05 00:38:38   \n",
       "76    0801908047    KKF44CYBRFOXT57S          82.0 2024-01-05 02:38:38   \n",
       "\n",
       "    FUGA_DETECTADA  FUGA_REITERADA  ... PRECIPITACION_LAG_1H  \\\n",
       "72             0.0             0.0  ...                  0,3   \n",
       "73             0.0             0.0  ...                  0,3   \n",
       "74             0.0             0.0  ...                  0,3   \n",
       "75             0.0             0.0  ...                  0,3   \n",
       "76             0.0             0.0  ...                  8,4   \n",
       "\n",
       "   PRECIPITACION_LAG_6H PRECIPITACION_LAG_12H PRECIPITACION_LAG_24H  \\\n",
       "72                  0,3                   0,3                   0,0   \n",
       "73                  0,3                   0,3                   0,0   \n",
       "74                  0,3                   0,3                   0,0   \n",
       "75                  0,3                   0,3                   0,0   \n",
       "76                  0,3                   0,3                   0,0   \n",
       "\n",
       "   PRECIPITACION_LAG_72H CONSUMO_ROLLING_MEAN_7D  CONSUMO_ROLLING_STD_7D  \\\n",
       "72                   0,0               92.164384               28.278876   \n",
       "73                   0,0               92.581081               28.312351   \n",
       "74                   0,0               92.986667               28.338920   \n",
       "75                   0,0               92.842105               28.177557   \n",
       "76                   0,0               92.701299               28.018821   \n",
       "\n",
       "    TARGET_HOY TARGET_MANANA TARGET_7DIAS  \n",
       "72         0.0           0.0          0.0  \n",
       "73         0.0           0.0          0.0  \n",
       "74         0.0           0.0          0.0  \n",
       "75         0.0           0.0          0.0  \n",
       "76         0.0           0.0          0.0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5f2e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_duplicados = ['POLISSA_SUBM', 'FECHA', 'HORA']\n",
    "df = df.drop_duplicates(subset=subset_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865fe6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3. Carga Distribuida y Muestreo ---\n",
      "ERROR CRÍTICO: An error occurred while calling the read_parquet method registered to the pandas backend.\n",
      "Original Message: c:/Users/barco/OneDrive/Documentos/GitHub/GeSAI-AB_Data_Challenge/project-notebooks/../data/processed/dataset_FINAL_COMPLETO.parquet\n",
      "Ordenando cronológicamente...\n",
      "\n",
      "--- 4. Ingeniería de Características ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creando Lags: 100%|██████████| 3/3 [00:03<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Finales (43): ['CONSUMO_REAL', 'FESTIVO', 'TIPO_DIA', 'US_AIGUA_SUBM', 'TEMP_MEDIA'] ...\n",
      "Train: 3514661 | Test: 878666\n",
      "\n",
      "--- 6. ENTRENAMIENTO ---\n",
      "\n",
      "[PROCESANDO] TARGET_HOY...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.971684\n",
      "\n",
      "[PROCESANDO] TARGET_MANANA...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.966413\n",
      "\n",
      "[PROCESANDO] TARGET_7DIAS...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.945164\n",
      "\n",
      "--- 7. EVALUACIÓN FINAL (TEST SET) ---\n",
      "\n",
      ">>> RESULTADOS TARGET_HOY <<<\n",
      "AUC-PR: 0.7037 | AUC-ROC: 0.6363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Fuga       0.51      0.70      0.59    376311\n",
      "        Fuga       0.69      0.49      0.57    502355\n",
      "\n",
      "    accuracy                           0.58    878666\n",
      "   macro avg       0.60      0.60      0.58    878666\n",
      "weighted avg       0.61      0.58      0.58    878666\n",
      "\n",
      "\n",
      ">>> RESULTADOS TARGET_MANANA <<<\n",
      "AUC-PR: 0.6933 | AUC-ROC: 0.6343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Fuga       0.51      0.71      0.59    376362\n",
      "        Fuga       0.69      0.49      0.57    502304\n",
      "\n",
      "    accuracy                           0.58    878666\n",
      "   macro avg       0.60      0.60      0.58    878666\n",
      "weighted avg       0.61      0.58      0.58    878666\n",
      "\n",
      "\n",
      ">>> RESULTADOS TARGET_7DIAS <<<\n",
      "AUC-PR: 0.6916 | AUC-ROC: 0.6347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Fuga       0.51      0.70      0.59    376699\n",
      "        Fuga       0.69      0.50      0.58    501967\n",
      "\n",
      "    accuracy                           0.59    878666\n",
      "   macro avg       0.60      0.60      0.59    878666\n",
      "weighted avg       0.62      0.59      0.59    878666\n",
      "\n",
      "\n",
      "✅ ENTRENAMIENTO COMPLETADO.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- 0. Configuración y Librerías ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# --- 1. CONFIGURACIÓN DEL PROYECTO ---\n",
    "FINAL_DATASET_PATH = '../data/processed/dataset_FINAL_COMPLETO.parquet'\n",
    "ID_COLUMN = 'POLISSA_SUBM'\n",
    "\n",
    "HORIZONTES_PREDICCION = {'HOY': 1, 'MANANA': 24, '7DIAS': 168}\n",
    "\n",
    "# Memoria: Usamos el 10% de los datos para evitar ArrowMemoryError\n",
    "SUBSAMPLE_PERCENT = 0.10 \n",
    "\n",
    "# --- 2. DEFINICIÓN DE FEATURES (LIMPIEZA Y ORDENACIÓN) ---\n",
    "\n",
    "# 2.1. Columnas a EXCLUIR explícitamente (Metadata y Redundantes)\n",
    "# Eliminamos: IDs, Fechas, Targets, y las redundantes (Temp Min/Max, Población Absoluta)\n",
    "EXCLUDED_COLS = [\n",
    "    # Metadata y Claves\n",
    "    'POLISSA_SUBM', 'NUMEROSERIECONTADOR', 'SECCIO_CENSAL', 'KEY_DISTRITO', 'KEY_SECCION', \n",
    "    'FECHA_HORA', 'FECHA', 'HORA', 'FECHA_HORA_CRONO', \n",
    "    # Fechas Administrativas (Sin valor predictivo horario)\n",
    "    'DATA_INI_FACT', 'DATA_FIN_FACT', \n",
    "    # Targets\n",
    "    'FUGA_DETECTADA', 'FUGA_REITERADA', \n",
    "    # Redundancias Climáticas (Alta correlación con Media)\n",
    "    'TEMP_MIN', 'TEMP_MAX', \n",
    "    # Redundancias Demográficas (Usamos Porcentajes en su lugar)\n",
    "    'Pob_0_14_anys', 'Pob_15_24_anys', 'Pob_25_39_anys', 'Pob_40_64_anys', 'Pob_65_o_mas'\n",
    "]\n",
    "\n",
    "# 2.2. Lista Ordenada de Features Base (23 Columnas)\n",
    "FEATURE_COLUMNS_BASE = [\n",
    "    # Core\n",
    "    'CONSUMO_REAL', \n",
    "    # Contexto\n",
    "    'FESTIVO', 'TIPO_DIA', 'US_AIGUA_SUBM',\n",
    "    # Clima\n",
    "    'TEMP_MEDIA', 'PRECIPITACION', 'HUMEDAD_RELATIVA_MEDIA',\n",
    "    # Socioeconómico\n",
    "    'Renda_Media_Euros', 'Num_Obres_Recents', 'Pob_Total_Seccio',\n",
    "    # Demografía (Perfil)\n",
    "    'Pct_Pob_0_14_anys', 'Pct_Pob_15_24_anys', 'Pct_Pob_25_39_anys', \n",
    "    'Pct_Pob_40_64_anys', 'Pct_Pob_65_o_mas',\n",
    "    # Infraestructura (Antigüedad)\n",
    "    'Antig_Menor_1901', 'Antig_1901_a_1940', 'Antig_1941_a_1950', 'Antig_1951_a_1960',\n",
    "    'Antig_1961_a_1970', 'Antig_1971_a_1980', 'Antig_1981_a_1990', 'Antig_1991_a_2000',\n",
    "    'Antig_2001_a_2010', 'Antig_2011_a_2020', 'Antig_2021_a_2030'\n",
    "]\n",
    "\n",
    "# --- 3. Carga y Muestreo del Dataset (DASK) ---\n",
    "print(\"--- 3. Carga Distribuida y Muestreo ---\")\n",
    "\n",
    "try:\n",
    "    df_dask_full = dd.read_parquet(FINAL_DATASET_PATH)\n",
    "    print(f\"Aplicando muestreo del {SUBSAMPLE_PERCENT:.0%}...\")\n",
    "    df_dask_sampled = df_dask_full.sample(frac=SUBSAMPLE_PERCENT, random_state=42)\n",
    "    df = df_dask_sampled.compute()\n",
    "    print(f\"Dataset cargado en RAM: {df.shape[0]} filas.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR CRÍTICO: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 3.1. Ordenamiento Cronológico\n",
    "print(\"Ordenando cronológicamente...\")\n",
    "df['FECHA_HORA_CRONO'] = pd.to_datetime(df['FECHA'].astype(str) + ' ' + df['HORA'].astype(str), errors='coerce')\n",
    "df = df.sort_values(by=[ID_COLUMN, 'FECHA_HORA_CRONO']).reset_index(drop=True)\n",
    "\n",
    "# --- 4. Ingeniería de Características (Feature Engineering) ---\n",
    "print(\"\\n--- 4. Ingeniería de Características ---\")\n",
    "\n",
    "# Filtramos el DF para quedarnos solo con las columnas base antes de generar lags\n",
    "# (Esto ahorra memoria antes de duplicar columnas)\n",
    "cols_to_keep = FEATURE_COLUMNS_BASE + [ID_COLUMN, 'FECHA_HORA_CRONO', 'FUGA_DETECTADA']\n",
    "# Solo mantenemos las que existen en el DF\n",
    "cols_to_keep = [c for c in cols_to_keep if c in df.columns]\n",
    "df = df[cols_to_keep]\n",
    "\n",
    "# 4.1. Lags (Historia)\n",
    "LAG_FEATURES = ['CONSUMO_REAL', 'TEMP_MEDIA', 'PRECIPITACION']\n",
    "LAG_STEPS = [1, 6, 12, 24, 72] \n",
    "\n",
    "for col in tqdm(LAG_FEATURES, desc=\"Creando Lags\"):\n",
    "    for lag in LAG_STEPS:\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_LAG_{lag}H'] = df.groupby(ID_COLUMN)[col].shift(lag)\n",
    "\n",
    "# 4.2. Rolling (Tendencias)\n",
    "WINDOW_SIZE = 168\n",
    "if 'CONSUMO_REAL' in df.columns:\n",
    "    df['CONSUMO_ROLLING_MEAN_7D'] = df.groupby(ID_COLUMN)['CONSUMO_REAL'].transform(lambda x: x.rolling(WINDOW_SIZE, min_periods=1).mean())\n",
    "    df['CONSUMO_ROLLING_STD_7D'] = df.groupby(ID_COLUMN)['CONSUMO_REAL'].transform(lambda x: x.rolling(WINDOW_SIZE, min_periods=1).std())\n",
    "\n",
    "# 4.3. Targets\n",
    "TARGET_COLS = ['TARGET_HOY', 'TARGET_MANANA', 'TARGET_7DIAS']\n",
    "df['TARGET_HOY'] = df['FUGA_DETECTADA'].shift(-1)\n",
    "df['TARGET_MANANA'] = df['FUGA_DETECTADA'].shift(-24)\n",
    "df['TARGET_7DIAS'] = df['FUGA_DETECTADA'].shift(-168)\n",
    "\n",
    "# --- 5. Definición Final de X e y ---\n",
    "# Recopilamos todas las features generadas\n",
    "X_COLS = [c for c in df.columns if c not in EXCLUDED_COLS and c not in TARGET_COLS + ['FUGA_DETECTADA', ID_COLUMN, 'FECHA_HORA_CRONO']]\n",
    "\n",
    "print(f\"Features Finales ({len(X_COLS)}): {X_COLS[:5]} ...\")\n",
    "\n",
    "# Limpieza de NaNs\n",
    "df = df.dropna(subset=['TARGET_7DIAS'] + X_COLS)\n",
    "\n",
    "# Definición de Categóricas\n",
    "CATEGORICAL_COLS = ['US_AIGUA_SUBM', 'TIPO_DIA']\n",
    "for col in CATEGORICAL_COLS:\n",
    "    if col in X_COLS:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "# Time Split\n",
    "split_index = int(len(df) * 0.80)\n",
    "df_train = df.iloc[:split_index].copy()\n",
    "df_test = df.iloc[split_index:].copy()\n",
    "\n",
    "print(f\"Train: {len(df_train)} | Test: {len(df_test)}\")\n",
    "\n",
    "# --- 6. Entrenamiento ---\n",
    "print(\"\\n--- 6. ENTRENAMIENTO ---\")\n",
    "modelos_finales = {}\n",
    "output_dir = '../data/modelos_finales/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for target_col in TARGET_COLS:\n",
    "    print(f\"\\n[PROCESANDO] {target_col}...\")\n",
    "    \n",
    "    # Preparar datos\n",
    "    X = df_train[X_COLS].copy()\n",
    "    y = df_train[target_col].astype(int)\n",
    "    \n",
    "    # Limpieza de tipos (Anti-ValueError)\n",
    "    num_cols = [c for c in X_COLS if c not in CATEGORICAL_COLS]\n",
    "    for col in num_cols:\n",
    "        if X[col].dtype == 'object':\n",
    "            X[col] = X[col].astype(str).str.replace(',', '.', regex=False)\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce').fillna(0.0)\n",
    "\n",
    "    # División interna\n",
    "    X_fit, X_val, y_fit, y_val = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
    "    \n",
    "    # LightGBM\n",
    "    lgbm = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='auc', \n",
    "        is_unbalance=True,\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    lgbm.fit(\n",
    "        X_fit, y_fit,\n",
    "        categorical_feature=[c for c in X_COLS if c in CATEGORICAL_COLS],\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[lgb.early_stopping(50, verbose=True)]\n",
    "    )\n",
    "    \n",
    "    modelos_finales[target_col] = lgbm\n",
    "    joblib.dump(lgbm, os.path.join(output_dir, f'lgbm_model_{target_col}.joblib'))\n",
    "\n",
    "# --- 7. Evaluación Final ---\n",
    "print(\"\\n--- 7. EVALUACIÓN FINAL (TEST SET) ---\")\n",
    "\n",
    "# Preparamos X_test\n",
    "X_test_final = df_test[X_COLS].copy()\n",
    "for col in num_cols:\n",
    "    if X_test_final[col].dtype == 'object':\n",
    "        X_test_final[col] = X_test_final[col].astype(str).str.replace(',', '.', regex=False)\n",
    "    X_test_final[col] = pd.to_numeric(X_test_final[col], errors='coerce').fillna(0.0)\n",
    "\n",
    "for target_col, modelo in modelos_finales.items():\n",
    "    y_test_final = df_test[target_col].astype(int)\n",
    "    y_pred_proba = modelo.predict_proba(X_test_final)[:, 1]\n",
    "    \n",
    "    auc_pr = average_precision_score(y_test_final, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_test_final, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\n>>> RESULTADOS {target_col} <<<\")\n",
    "    print(f\"AUC-PR: {auc_pr:.4f} | AUC-ROC: {roc_auc:.4f}\")\n",
    "    \n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    print(classification_report(y_test_final, y_pred, target_names=['No Fuga', 'Fuga']))\n",
    "\n",
    "print(\"\\n✅ ENTRENAMIENTO COMPLETADO.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d60c9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
